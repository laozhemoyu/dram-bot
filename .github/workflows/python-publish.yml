import os
import time
import hmac
import hashlib
import base64
import urllib.parse
import requests
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup

# è¯»å– Secrets
WEBHOOK = os.environ.get("DING_WEBHOOK")
SECRET = os.environ.get("DING_SECRET")

def send_dingtalk_markdown(title, content):
    if not WEBHOOK or not SECRET:
        print("âŒ é”™è¯¯: æœªè¯»å–åˆ°é’‰é’‰é…ç½®")
        return
    timestamp = str(round(time.time() * 1000))
    secret_enc = SECRET.encode('utf-8')
    string_to_sign = '{}\n{}'.format(timestamp, SECRET)
    string_to_sign_enc = string_to_sign.encode('utf-8')
    hmac_code = hmac.new(secret_enc, string_to_sign_enc, digestmod=hashlib.sha256).digest()
    sign = urllib.parse.quote_plus(base64.b64encode(hmac_code))
    url = f"{WEBHOOK}&timestamp={timestamp}&sign={sign}"
    headers = {'Content-Type': 'application/json'}
    data = {"msgtype": "markdown", "markdown": {"title": title, "text": content}}
    try:
        requests.post(url, headers=headers, json=data, timeout=10)
        print("âœ… æ¨é€æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ¨é€å¤±è´¥: {e}")

def generate_report(data_list):
    if not data_list: return "æš‚æ— æ•°æ®"
    parsed = []
    for item in data_list:
        try:
            parts = item.split("|")
            val = float(parts[2].replace("æ¶¨è·Œ:", "").replace("%", "").strip())
            parsed.append({"raw": item, "val": val})
        except: continue
    
    up = sorted([x for x in parsed if x['val'] > 0], key=lambda x: x['val'], reverse=True)
    down = sorted([x for x in parsed if x['val'] < 0], key=lambda x: x['val'])
    flat = [x for x in parsed if x['val'] == 0]
    
    lines = [f"## ğŸ“Š DRAM è¡Œæƒ… (GitHubç‰ˆ)", f"> æ—¶é—´: {time.strftime('%H:%M')}", "---"]
    
    def add_section(items, title, icon):
        if items:
            lines.append(f"### {icon} {title} ({len(items)})")
            for item in items:
                parts = item['raw'].split("|")
                name = parts[0].strip()
                price = parts[1].replace("å‡ä»·:", "").strip()
                change = parts[2].replace("æ¶¨è·Œ:", "").strip()
                lines.append(f"**{name}**\n- ğŸ’° `{price}` ({change})\n")

    add_section(up, "é¢†æ¶¨", "ğŸ”´")
    add_section(down, "é¢†è·Œ", "ğŸ’š")
    
    if flat:
        lines.append(f"### â– æŒå¹³ ({len(flat)})")
        for x in flat:
            parts = x['raw'].split("|")
            lines.append(f"- {parts[0].strip()}")
    return "\n".join(lines)

def scrape_data():
    options = Options()
    options.add_argument("--headless=new")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--window-size=1920,1080")
    options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    
    # GitHub Actions è‡ªå¸¦ Chromeï¼Œä¸éœ€è¦æŒ‡å®šè·¯å¾„
    driver = webdriver.Chrome(options=options)
    
    try:
        print("ğŸŒ è®¿é—® TrendForce...")
        driver.get("https://www.trendforce.cn/price")
        time.sleep(5)
        try:
            btn = WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.XPATH, "//*[contains(text(), 'DRAM')]")))
            driver.execute_script("arguments[0].click();", btn)
            time.sleep(3)
        except: pass
        
        soup = BeautifulSoup(driver.page_source, 'html.parser')
        res = []
        for row in soup.select('table tbody tr') or soup.select('table tr'):
            cols = row.find_all(['th', 'td'])
            if len(cols) < 7: continue
            name = cols[0].get_text(strip=True)
            if 'DDR' in name.upper():
                try:
                    p = cols[5].get_text(strip=True)
                    c = cols[6].get_text(strip=True)
                    res.append(f"{name} | å‡ä»·:{p} | æ¶¨è·Œ:{c}")
                except: continue
        return res
    except Exception as e:
        print(f"Error: {e}")
        return []
    finally:
        driver.quit()

if __name__ == "__main__":
    data = scrape_data()
    if data:
        rpt = generate_report(data)
        send_dingtalk_markdown("DRAMæ—¥æŠ¥", rpt)
    else:
        print("æœªæŠ“å–åˆ°æ•°æ®")
