import os
import time
import datetime
import hmac
import hashlib
import base64
import urllib.parse
import requests
import matplotlib.pyplot as plt
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup

# ==========================================
# ğŸ”‘ ç¯å¢ƒå˜é‡
# ==========================================
WEBHOOK = os.environ.get("DING_WEBHOOK")
SECRET = os.environ.get("DING_SECRET")

# è®¾ç½®ä¸­æ–‡å­—ä½“ (é€‚é… GitHub Linux ç¯å¢ƒ)
plt.rcParams['font.sans-serif'] = ['Noto Sans CJK JP', 'SimHei', 'Arial Unicode MS', 'sans-serif']
plt.rcParams['axes.unicode_minus'] = False 

def upload_image_to_host(file_path):
    """ä¸Šä¼ å›¾ç‰‡åˆ°å›¾åºŠ"""
    try:
        print("ğŸ“¤ æ­£åœ¨ä¸Šä¼ åˆ†ææŠ¥å‘Š...")
        with open(file_path, 'rb') as f:
            files = {'file': f}
            # ä½¿ç”¨ vim-cn å…è´¹å›¾åºŠ
            response = requests.post('https://img.vim-cn.com/', files=files, timeout=30)
            if response.status_code == 200:
                img_url = response.text.strip().replace('http://', 'https://')
                print(f"âœ… å›¾ç‰‡é“¾æ¥: {img_url}")
                return img_url
    except Exception as e:
        print(f"âŒ å›¾ç‰‡ä¸Šä¼ å¤±è´¥: {e}")
    return None

def draw_summary_report(data_list):
    """
    ğŸ¨ ç»˜åˆ¶ã€å¸‚åœºåˆ†å¸ƒæ±‡æ€»æŠ¥å‘Šã€‘(ä»¿ç”¨æˆ·æˆªå›¾æ ·å¼)
    """
    if not data_list: return None
    print("ğŸ¨ æ­£åœ¨ç»˜åˆ¶æ±‡æ€»æŠ¥å‘Š...")

    # 1. æ•°æ®åˆ†ç±»
    rising = []
    falling = []
    flat = []

    for item in data_list:
        # item: [name, ..., change]
        name = item[0]
        # ç®€åŒ–åå­—ï¼šå»æ‰å†—ä½™çš„ DDR å‰ç¼€ï¼Œè®©åˆ—è¡¨æ›´æ¸…çˆ½
        short_name = name.replace("DDR", "D") 
        if len(short_name) > 25: short_name = short_name[:22] + "..."
        
        change = item[6]
        
        # æ ¼å¼åŒ–æ˜¾ç¤ºæ–‡æœ¬ï¼š "â€¢ D5 16G..., +3.27%"
        display_str = f"â€¢ {short_name}, {change}"
        
        if "-" in change and change != "-":
             falling.append(display_str)
        elif "0%" in change or change == "-":
             flat.append(display_str)
        else:
             rising.append(display_str)

    # 2. å‡†å¤‡è¡¨æ ¼å†…å®¹ (æ¯è¡Œ 4 åˆ—)
    # é™åˆ¶åˆ—è¡¨é•¿åº¦ï¼Œé˜²æ­¢å›¾ç‰‡æ— é™æ‹‰é•¿
    MAX_SHOW = 12 
    def format_list(lst):
        if not lst: return "-"
        if len(lst) > MAX_SHOW:
            return "\n".join(lst[:MAX_SHOW]) + f"\n... (Total {len(lst)})"
        return "\n".join(lst)

    # å®šä¹‰ä¸‰è¡Œæ•°æ®
    # [Trend, Count, List, Status]
    rows_data = [
        ["â¬† Rising (æ¶¨)", len(rising), format_list(rising), "Positive"],
        ["â¬‡ Falling (è·Œ)", len(falling), format_list(falling), "Negative"],
        ["â¡ Unchanged\n(å¹³)", len(flat), format_list(flat), "Neutral"]
    ]
    
    col_labels = ["Market Trend", "Product Count", "Product List (Examples)", "Status"]
    row_colors = ['#d62728', '#2ca02c', '#555555'] # çº¢ã€ç»¿ã€ç°

    # 3. åŠ¨æ€è®¡ç®—é«˜åº¦ (æ ¸å¿ƒç®—æ³•)
    # è®¡ç®—æ¯ä¸€è¡Œæœ‰å¤šå°‘è¡Œæ–‡å­—
    line_counts = [r[2].count('\n') + 1 for r in rows_data]
    # ç»™è¡¨å¤´ç•™ 2 è¡Œçš„é«˜åº¦
    total_text_lines = sum(line_counts) + 3 
    
    # å›¾ç‰‡é«˜åº¦ï¼šæ¯è¡Œæ–‡å­—çº¦å  0.35 è‹±å¯¸ï¼Œæœ€å° 5 è‹±å¯¸
    fig_height = max(5, total_text_lines * 0.4)
    
    # åˆ›å»ºç”»å¸ƒ
    fig, ax = plt.subplots(figsize=(12, fig_height))
    ax.axis('off')

    # 4. ç»˜åˆ¶è¡¨æ ¼
    table = ax.table(
        cellText=rows_data,
        colLabels=col_labels,
        cellLoc='left',
        loc='center',
        colWidths=[0.15, 0.12, 0.58, 0.15] # åˆ—å®½æ¯”ä¾‹
    )

    # 5. æ·±åº¦ç¾åŒ–è¡¨æ ¼æ ·å¼
    table.auto_set_font_size(False)
    table.set_fontsize(11)
    
    cells = table.get_celld()
    
    # è®¡ç®—ç›¸å¯¹é«˜åº¦æ¯”ä¾‹ (ä¸ºäº†è®©è¡Œé«˜éšå†…å®¹è‡ªåŠ¨æ’‘å¼€)
    # è¡¨å¤´å æ€»é«˜åº¦çš„æ¯”ä¾‹
    header_ratio = 2 / total_text_lines 
    
    # è®¾ç½®è¡¨å¤´æ ·å¼
    for j in range(4):
        cell = cells[(0, j)]
        cell.set_height(header_ratio)
        cell.set_text_props(weight='bold')
        cell.set_facecolor('#f0f0f0') # æµ…ç°èƒŒæ™¯
        cell.set_edgecolor('black')
        cell._loc = 'center' # æ–‡å­—å±…ä¸­

    # è®¾ç½®æ•°æ®è¡Œæ ·å¼
    for i, line_count in enumerate(line_counts):
        row_idx = i + 1
        # è®¡ç®—è¯¥è¡Œåº”å çš„é«˜åº¦æ¯”ä¾‹
        row_ratio = line_count / total_text_lines
        
        for j in range(4):
            cell = cells[(row_idx, j)]
            cell.set_height(row_ratio)
            
            # ç¬¬1åˆ— (Trend): è®¾ç½®é¢œè‰²ã€å±…ä¸­ã€åŠ ç²—
            if j == 0:
                cell.set_text_props(color=row_colors[i], weight='bold', ha='center', size=12)
            
            # ç¬¬2åˆ— (Count): å±…ä¸­
            if j == 1:
                cell.set_text_props(ha='center', size=12)
                
            # ç¬¬3åˆ— (List): å·¦å¯¹é½ï¼Œè°ƒæ•´å†…è¾¹è·
            if j == 2:
                # ç»™æ–‡å­—åŠ ä¸€ç‚¹å·¦è¾¹è·ï¼Œé˜²æ­¢è´´ç€çº¿
                text_obj = cell.get_text()
                text_obj.set_x(0.02) 
            
            # ç¬¬4åˆ— (Status): å±…ä¸­
            if j == 3:
                cell.set_text_props(ha='center')

    # 6. æ·»åŠ é¡µçœ‰é¡µè„š
    total_count = len(data_list)
    sentiment = "Mixed"
    if len(rising) > len(falling): sentiment = "Bullish (Upward)"
    elif len(falling) > len(rising): sentiment = "Bearish (Downward)"
    
    # æ ‡é¢˜
    plt.title(f"DRAM Market Distribution Report ({total_count} Products)", fontsize=16, weight='bold', y=0.98)
    
    # åº•éƒ¨ç»Ÿè®¡æ 
    footer_text = f"Total Products: {total_count}  |  Overall Sentiment: {sentiment}"
    plt.figtext(0.5, 0.02, footer_text, ha="center", fontsize=12, 
                bbox={"facecolor":"#e6f4ff", "edgecolor":"none", "pad":8, "alpha":0.5})
    
    # å³ä¸‹è§’æ—¶é—´
    timestamp = datetime.datetime.now().strftime("%Y-%m-%d")
    plt.figtext(0.95, 0.01, f"Last Update: {timestamp}", ha="right", fontsize=9, color="grey")

    # ä¿å­˜
    filename = "summary_report.png"
    plt.savefig(filename, bbox_inches='tight', dpi=150, pad_inches=0.2)
    plt.close()
    print("âœ… æ±‡æ€»è¡¨æ ¼å›¾ç‰‡å·²ç”Ÿæˆ")
    return filename

def send_dingtalk_markdown(title, img_url):
    """å‘é€å›¾ç‰‡æ¶ˆæ¯"""
    if not WEBHOOK or not SECRET: return
    timestamp = str(round(time.time() * 1000))
    secret_enc = SECRET.encode('utf-8')
    string_to_sign = '{}\n{}'.format(timestamp, SECRET)
    string_to_sign_enc = string_to_sign.encode('utf-8')
    hmac_code = hmac.new(secret_enc, string_to_sign_enc, digestmod=hashlib.sha256).digest()
    sign = urllib.parse.quote_plus(base64.b64encode(hmac_code))
    url = f"{WEBHOOK}&timestamp={timestamp}&sign={sign}"
    
    content = f"### ğŸ“Š {title}\n> å¸‚åœºæƒ…ç»ª: è‡ªåŠ¨åˆ†æ\n> æ›´æ–°æ—¶é—´: {time.strftime('%H:%M')}\n\n![è¡Œæƒ…è¡¨]({img_url})"
    headers = {'Content-Type': 'application/json'}
    data = {"msgtype": "markdown", "markdown": {"title": title, "text": content}}
    try:
        requests.post(url, headers=headers, json=data, timeout=15)
        print("âœ… æ¨é€æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ¨é€å¤±è´¥: {e}")

def scrape_data():
    """Chrome çˆ¬è™«"""
    options = Options()
    options.add_argument("--headless=new")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--window-size=1920,1080")
    options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    driver = webdriver.Chrome(options=options)
    try:
        print("ğŸŒ è®¿é—® TrendForce...")
        driver.get("https://www.trendforce.cn/price")
        time.sleep(5)
        try:
            btn = WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.XPATH, "//*[contains(text(), 'DRAM')]")))
            driver.execute_script("arguments[0].click();", btn)
            time.sleep(3)
        except: pass
        
        soup = BeautifulSoup(driver.page_source, 'html.parser')
        raw_rows = []
        rows = soup.select('table tbody tr') or soup.select('table tr')
        for row in rows:
            cols = row.find_all(['th', 'td'])
            if len(cols) < 7: continue
            p_name = cols[0].get_text(strip=True)
            if 'DDR' in p_name.upper():
                row_data = [
                    p_name,
                    cols[1].get_text(strip=True),
                    cols[2].get_text(strip=True),
                    cols[3].get_text(strip=True),
                    cols[4].get_text(strip=True),
                    cols[5].get_text(strip=True),
                    cols[6].get_text(strip=True)
                ]
                raw_rows.append(row_data)
        return raw_rows
    except Exception as e:
        print(f"Error: {e}")
        return []
    finally:
        driver.quit()

if __name__ == "__main__":
    print("ğŸš€ å¯åŠ¨æ±‡æ€»æŠ¥å‘Šä»»åŠ¡...")
    data = scrape_data()
    if data:
        print(f"âœ… æŠ“å–åˆ° {len(data)} æ¡æ•°æ®")
        img_path = draw_summary_report(data)
        if img_path:
            url = upload_image_to_host(img_path)
            if url:
                send_dingtalk_markdown("DRAM å¸‚åœºåˆ†å¸ƒæŠ¥å‘Š", url)
    else:
        print("âŒ æœªæŠ“å–åˆ°æ•°æ®")
