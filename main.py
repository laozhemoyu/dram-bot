import os, time, hmac, hashlib, base64, urllib.parse, requests, logging
import matplotlib.pyplot as plt
from selenium import webdriver
from selenium.webdriver.edge.options import Options as EdgeOptions
from selenium.webdriver.edge.service import Service as EdgeService
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup
from openai import OpenAI

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
logger = logging.getLogger(__name__)

# ç¯å¢ƒé…ç½®
WEBHOOK = os.environ.get("DING_WEBHOOK")
SECRET = os.environ.get("DING_SECRET")
AI_API_KEY = os.environ.get("AI_API_KEY")
AI_BASE_URL = os.environ.get("AI_BASE_URL", "https://api.deepseek.com")

def configure_fonts():
    plt.rcParams['font.sans-serif'] = ['WenQuanYi Micro Hei', 'DejaVu Sans']
    plt.rcParams['axes.unicode_minus'] = False

def scrape_trendforce():
    options = EdgeOptions()
    options.add_argument("--headless=new")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36 Edg/122.0.0.0")
    
    # ğŸ”¥ æ ¸å¿ƒä¿®å¤ï¼šç›´æ¥è°ƒç”¨ç³»ç»Ÿé¢„è£…çš„ msedgedriverï¼Œåˆ æ‰ DriverManager().install()
    # GitHub Actions ubuntu ç¯å¢ƒé€šè¿‡ apt å®‰è£…åï¼Œè·¯å¾„å°±åœ¨ /usr/bin/msedgedriver
    try:
        service = EdgeService(executable_path='/usr/bin/msedgedriver')
        driver = webdriver.Edge(service=service, options=options)
    except Exception as e:
        logger.warning(f"æŒ‡å®šè·¯å¾„å¯åŠ¨å¤±è´¥ï¼Œå°è¯•é»˜è®¤æ¨¡å¼: {e}")
        driver = webdriver.Edge(options=options)
    
    results = {}
    try:
        logger.info("ğŸ“¡ æ­£åœ¨å®æ—¶è®¿é—® TrendForce å®˜ç½‘...")
        driver.get("https://www.trendforce.cn/price")
        
        # ç­‰å¾…è¡¨æ ¼åŠ è½½
        WebDriverWait(driver, 45).until(EC.presence_of_element_located((By.TAG_NAME, "table")))
        
        # å¼ºåˆ¶å‘ä¸‹æ»šåŠ¨ï¼Œç¡®ä¿åº•éƒ¨çš„ SSD æ¨¡å—è¢«è§¦å‘åŠ è½½
        for scroll in [1000, 2000]:
            driver.execute_script(f"window.scrollTo(0, {scroll});")
            time.sleep(5)
        
        soup = BeautifulSoup(driver.page_source, 'html.parser')
        targets = {"DRAM": "DRAM ç°è´§ä»·æ ¼", "NAND Flash": "NAND Flash ç°è´§ä»·æ ¼", "SSD": "æˆå“ç°è´§ä»·æ ¼"}
        
        for key, title_text in targets.items():
            anchor = soup.find(lambda tag: tag.name in ['div', 'span', 'h3'] and title_text in tag.text)
            if anchor:
                table = anchor.find_next('table')
                if table:
                    headers = [th.get_text(strip=True) for th in table.find_all('th')]
                    rows = []
                    for tr in table.find_all('tr')[1:]:
                        cells = tr.find_all('td')
                        if len(cells) >= 2:
                            # ä¿®å¤ä¹‹å‰å‡ºç°çš„â€œå‹å·æ˜¾ç¤ºä¸ºæ•°å­—â€çš„é—®é¢˜
                            line = []
                            for i, td in enumerate(cells):
                                # ä¼˜å…ˆæŠ“å– title å±æ€§ï¼Œè¿™é€šå¸¸åŒ…å«å®Œæ•´çš„å‹å·åç§°
                                txt = td.get('title') or td.get_text(" ", strip=True)
                                line.append(txt)
                            if len(line[0]) > 3: # è¿‡æ»¤æ— æ•ˆè¡Œ
                                rows.append(line[:len(headers)])
                    
                    if rows:
                        results[key] = {"headers": headers, "rows": rows}
                        logger.info(f"âœ… æˆåŠŸæŠ“å–: {key}")
    finally:
        driver.quit()
    return results

def draw_table(title, headers, rows):
    if not rows: return None
    # åŠ å®½ç”»å¸ƒé˜²æ­¢æ–‡å­—é‡å 
    fig, ax = plt.subplots(figsize=(16, len(rows)*0.55 + 2))
    ax.axis('off')
    table = ax.table(cellText=rows, colLabels=headers, loc='center', cellLoc='left')
    table.auto_set_font_size(False); table.set_fontsize(11); table.scale(1.2, 2.4)
    for (i, j), cell in table.get_celld().items():
        if i == 0: cell.set_facecolor('#D6EAF8'); cell.set_text_props(weight='bold', ha='center')
    path = f"{title}.png"
    plt.savefig(path, bbox_inches='tight', dpi=120); plt.close()
    return path

def get_ai_analysis(data):
    if not AI_API_KEY: return "AI Key æœªé…ç½®"
    try:
        client = OpenAI(api_key=AI_API_KEY, base_url=AI_BASE_URL)
        resp = client.chat.completions.create(model="deepseek-chat", messages=[{"role": "user", "content": f"æ€»ç»“è¡Œæƒ…ï¼š{str(data)[:1000]}"}])
        return resp.choices[0].message.content
    except: return "AI åˆ†ææš‚æ—¶ä¸å¯ç”¨"

def send_dingtalk(links, ai_text):
    if not WEBHOOK or not links: return
    ts = str(round(time.time() * 1000))
    sign = urllib.parse.quote_plus(base64.b64encode(hmac.new(SECRET.encode('utf-8'), f"{ts}\n{SECRET}".encode('utf-8'), hashlib.sha256).digest()))
    md = f"### ğŸ“Š å®æ—¶å­˜å‚¨è¡Œæƒ…æŠ¥å‘Š\n{ai_text}\n\n---\n"
    for cat in ["DRAM", "NAND Flash", "SSD"]:
        if cat in links: md += f"#### {cat}\n![{cat}]({links[cat]})\n\n"
    requests.post(f"{WEBHOOK}&timestamp={ts}&sign={sign}", json={"msgtype": "markdown", "markdown": {"title": "ä»·æ ¼ç›‘æ§", "text": md}})

if __name__ == "__main__":
    configure_fonts()
    res = scrape_trendforce()
    if res:
        ai = get_ai_analysis(res)
        img_links = {}
        for cat, content in res.items():
            p = draw_table(cat, content['headers'], content['rows'])
            if p:
                r = requests.post('https://catbox.moe/user/api.php', data={'reqtype': 'fileupload'}, files={'fileToUpload': open(p, 'rb')})
                if r.status_code == 200: img_links[cat] = r.text.strip()
        send_dingtalk(img_links, ai)
