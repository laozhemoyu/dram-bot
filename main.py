import os, time, hmac, hashlib, base64, urllib.parse, requests, logging
import matplotlib.pyplot as plt
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup
from openai import OpenAI

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
logger = logging.getLogger(__name__)

# ç¯å¢ƒé…ç½®
WEBHOOK = os.environ.get("DING_WEBHOOK")
SECRET = os.environ.get("DING_SECRET")
AI_API_KEY = os.environ.get("AI_API_KEY")
AI_BASE_URL = os.environ.get("AI_BASE_URL", "https://api.deepseek.com")

def configure_fonts():
    plt.rcParams['font.sans-serif'] = ['WenQuanYi Micro Hei', 'DejaVu Sans']
    plt.rcParams['axes.unicode_minus'] = False

def scrape_trendforce():
    chrome_options = Options()
    chrome_options.add_argument("--headless") # å¿…é¡»å¼€å¯æ— å¤´æ¨¡å¼
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    
    # ğŸ”¥ ç›´æ¥å¯åŠ¨ Chromeï¼ŒGitHub Actions ç¯å¢ƒä¼šè‡ªåŠ¨åŒ¹é…ç³»ç»Ÿè·¯å¾„
    driver = webdriver.Chrome(options=chrome_options)
    
    results = {}
    try:
        logger.info("ğŸ“¡ æ­£åœ¨å®æ—¶è®¿é—® TrendForce å®˜ç½‘æŠ“å–æ•°æ®...")
        driver.get("https://www.trendforce.cn/price")
        
        # ç­‰å¾…è¡¨æ ¼åŠ è½½
        WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.TAG_NAME, "table")))
        
        # æ¨¡æ‹Ÿæ»šåŠ¨ï¼Œç¡®ä¿æ‰€æœ‰æ¿å—ï¼ˆå¦‚ SSDï¼‰éƒ½åŠ è½½å‡ºæ¥
        for i in range(3):
            driver.execute_script(f"window.scrollTo(0, {800 * (i+1)});")
            time.sleep(2)
        
        soup = BeautifulSoup(driver.page_source, 'html.parser')
        targets = {"DRAM": "DRAM ç°è´§ä»·æ ¼", "NAND Flash": "NAND Flash ç°è´§ä»·æ ¼", "SSD": "æˆå“ç°è´§ä»·æ ¼"}
        
        for key, title_text in targets.items():
            anchor = soup.find(lambda tag: tag.name in ['div', 'span', 'h3'] and title_text in tag.text)
            if anchor:
                table = anchor.find_next('table')
                if table:
                    headers = [th.get_text(strip=True) for th in table.find_all('th')]
                    rows = []
                    for tr in table.find_all('tr')[1:]:
                        cells = tr.find_all('td')
                        if len(cells) >= 2:
                            line = []
                            for i, td in enumerate(cells):
                                # ğŸ”¥ æ ¸å¿ƒä¿®å¤ï¼šä¼˜å…ˆå– title å±æ€§ï¼Œè§£å†³â€œå‹å·å˜æ•°å­—â€é—®é¢˜
                                txt = td.get('title') or td.get_text(" ", strip=True)
                                line.append(txt)
                            if len(line[0]) > 3: # è¿‡æ»¤æ‰éæ•°æ®è¡Œ
                                rows.append(line[:len(headers)])
                    
                    if rows:
                        results[key] = {"headers": headers, "rows": rows}
                        logger.info(f"âœ… æŠ“å–æˆåŠŸ: {key}")
    finally:
        driver.quit()
    return results

def draw_table(title, headers, rows):
    if not rows: return None
    # åŠ¨æ€è°ƒæ•´é«˜åº¦
    fig, ax = plt.subplots(figsize=(15, len(rows)*0.6 + 2))
    ax.axis('off')
    table = ax.table(cellText=rows, colLabels=headers, loc='center', cellLoc='left')
    table.auto_set_font_size(False); table.set_fontsize(11); table.scale(1.2, 2.6)
    for (i, j), cell in table.get_celld().items():
        if i == 0: cell.set_facecolor('#D6EAF8'); cell.set_text_props(weight='bold', ha='center')
    path = f"{title}.png"
    plt.savefig(path, bbox_inches='tight', dpi=120); plt.close()
    return path

def get_ai_analysis(data):
    if not AI_API_KEY: return "AI é…ç½®ç¼ºå¤±"
    try:
        client = OpenAI(api_key=AI_API_KEY, base_url=AI_BASE_URL)
        resp = client.chat.completions.create(model="deepseek-chat", messages=[{"role": "user", "content": f"åˆ†æä»Šæ—¥è¡Œæƒ…ï¼š{str(data)[:1000]}"}])
        return resp.choices[0].message.content
    except: return "AI åˆ†ææš‚æ—¶ä¸å¯ç”¨"

def send_dingtalk(links, ai_text):
    if not WEBHOOK or not links: return
    ts = str(round(time.time() * 1000))
    sign = urllib.parse.quote_plus(base64.b64encode(hmac.new(SECRET.encode('utf-8'), f"{ts}\n{SECRET}".encode('utf-8'), hashlib.sha256).digest()))
    md = f"### ğŸ“Š å­˜å‚¨ä»·æ ¼ç›‘æ§ ({time.strftime('%Y-%m-%d')})\n{ai_text}\n\n"
    for cat in ["DRAM", "NAND Flash", "SSD"]:
        if cat in links: md += f"#### {cat}\n![{cat}]({links[cat]})\n\n"
    requests.post(f"{WEBHOOK}&timestamp={ts}&sign={sign}", json={"msgtype": "markdown", "markdown": {"title": "ä»·æ ¼å¿«æŠ¥", "text": md}})

if __name__ == "__main__":
    configure_fonts()
    res = scrape_trendforce()
    if res:
        ai_msg = get_ai_analysis(res)
        lnks = {}
        for cat, content in res.items():
            p = draw_table(cat, content['headers'], content['rows'])
            if p:
                r = requests.post('https://catbox.moe/user/api.php', data={'reqtype': 'fileupload'}, files={'fileToUpload': open(p, 'rb')})
                if r.status_code == 200: lnks[cat] = r.text.strip()
                os.remove(p)
        send_dingtalk(lnks, ai_msg)
